{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f8a23a5-df60-4a53-9ba5-a796ff08ba3b",
   "metadata": {},
   "source": [
    "## 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3616ba85-4be5-44f5-ac05-e17a70522409",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e471d562-5400-4e81-a5d5-5bb267796fba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# config\n",
    "root_dir = \"/mnt/d/Exa/227.건설 현장 위험 상태 판단 데이터/01-1.정식개방데이터/Minisample/\"\n",
    "makeset = tf.keras.utils.image_dataset_from_directory\n",
    "class_type = \"categorical\" # or \"categorical\"\n",
    "assert class_type in [\"binary\", \"categorical\"], \"typo in class_type\"\n",
    "\n",
    "# make dataset\n",
    "batch_size = 64\n",
    "image_size = (224, 224)\n",
    "seed = 9140183 # random number\n",
    "train_set = makeset(\n",
    "    f\"{root_dir}train\",\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    seed=seed,\n",
    "    label_mode=class_type\n",
    ")\n",
    "valid_set = makeset(\n",
    "    f\"{root_dir}validation\",\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    seed=seed,\n",
    "    label_mode=class_type\n",
    ")\n",
    "train_set.shuffle(buffer_size=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceffa007-8ac0-4b40-91cd-3a46ce4dc722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check dataset\n",
    "category_num = 0\n",
    "for d, l in train_set:\n",
    "    _, category_num = l.shape\n",
    "    print(f\"data batch size: {d.shape} / label batch size: {l.shape}\")\n",
    "    break\n",
    "if category_num == 1:\n",
    "\tassert class_type == \"binary\", \"분류 설정 오류\"\n",
    "elif category_num >= 2:\n",
    "\tassert class_type == \"categorical\", \"분류 설정 오류\"\n",
    "else:\n",
    "\traise Exception(\"검증 데이터셋 오류\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696b9c6a-200a-4494-b0f7-32207322d9f2",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22589a5-c04c-4832-82d3-7c0314c1b201",
   "metadata": {},
   "source": [
    "### Swish 활성화 함수 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c6f9a-f662-4bb2-a4ff-24a74a6b79d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(tf.keras.layers.Layer):\n",
    "    def call(self, x):\n",
    "        return x * tf.keras.activations.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd65f1-5eb7-493f-b426-5ac2106e82d4",
   "metadata": {},
   "source": [
    "### SEBlock 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247b8667-0fa6-455a-860f-24810d01f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SEBlock(reduction, channels, name):\n",
    "    def block(inputs):\n",
    "        x = layers.GlobalAveragePooling2D(name=f\"{name}_Squeeze\")(inputs)\n",
    "        x = layers.Reshape((1, 1, channels), name=f\"{name}_Reshape\")(x)\n",
    "        x = layers.Conv2D(channels // reduction, kernel_size=(1, 1), activation=Swish(), name=f\"{name}_Reduce\")(x)\n",
    "        x = layers.Conv2D(channels, kernel_size=(1, 1), activation=\"sigmoid\", name=f\"{name}_Expand\")(x)\n",
    "        x = layers.multiply([inputs, x], name=f\"{name}_Excite\")\n",
    "        return x\n",
    "    return block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faafa8bf-38a7-4bcf-9cfd-edaf17416f64",
   "metadata": {},
   "source": [
    "### MBConv 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589fe3d9-1a9f-4b8e-93cd-d18e0fa9c88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def MBConv(kernel_size, expansion, input_channels, output_channels, strides, name):\n",
    "    def block(inputs):\n",
    "        x = inputs\n",
    "        \n",
    "        if expansion > 1:\n",
    "            x = layers.Conv2D(filters=expansion * input_channels, kernel_size=(1, 1), use_bias=False, name=f\"{name}_Expansion\")(x)\n",
    "            x = layers.BatchNormalization(name=f\"{name}_BN-1\")(x)\n",
    "            x = Swish(name=f\"{name}_Swish-1\")(x)\n",
    "\n",
    "        x = layers.DepthwiseConv2D(kernel_size=kernel_size, use_bias=False, padding='same', strides=strides, name=f\"{name}_DWConv\")(x)\n",
    "        x = layers.BatchNormalization(name=f\"{name}_BN-2\")(x)\n",
    "        x = Swish(name=f\"{name}_Swish-2\")(x)\n",
    "        \n",
    "        x = SEBlock(reduction=expansion * 4, channels=input_channels * expansion, name=f\"{name}_SE\")(x)\n",
    "\n",
    "        x = layers.Conv2D(filters=output_channels, kernel_size=(1, 1), use_bias=False, name=f\"{name}_PWConv\")(x)\n",
    "        x = layers.BatchNormalization(name=f\"{name}_BN-3\")(x)\n",
    "        \n",
    "        if inputs.shape == x.shape:\n",
    "            x = layers.Dropout(0.2, name=f\"{name}_Dropout\")(x)\n",
    "            x = layers.add([x, inputs], name=f\"{name}_Add\")\n",
    "        return x\n",
    "    return block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a9bb2e-2ffd-4aa9-ab10-9b3e8911d320",
   "metadata": {},
   "source": [
    "### 모델 조립"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e7097-0e59-4fc5-aab9-d5ab57b9a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = [\n",
    "    # kernel_size, expansion, input_channels, output_channels, strides, name\n",
    "    # MBConv1, k3x3, C=16,  L=1\n",
    "    (3, 1, 32,  16,  1, \"Stage_2-1\"),\n",
    "    # MBConv6, k3x3, C=24,  L=2\n",
    "    (3, 6, 16,  24,  2, \"Stage_3-1\"),\n",
    "    (3, 6, 24,  24,  1, \"Stage_3-2\"),\n",
    "    # MBConv6, k5x5, C=40,  L=2\n",
    "    (5, 6, 24,  40,  2, \"Stage_4-1\"),\n",
    "    (5, 6, 40,  40,  1, \"Stage_4-2\"),\n",
    "    # MBConv6, k3x3, C=80,  L=3\n",
    "    (3, 6, 40,  80,  2, \"Stage_5-1\"),\n",
    "    (3, 6, 80,  80,  1, \"Stage_5-2\"),\n",
    "    (3, 6, 80,  80,  1, \"Stage_5-3\"),\n",
    "    # MBConv6, k5x5, C=112, L=3\n",
    "    (5, 6, 80,  112, 1, \"Stage_6-1\"),\n",
    "    (5, 6, 112, 112, 1, \"Stage_6-2\"),\n",
    "    (5, 6, 112, 112, 1, \"Stage_6-3\"),\n",
    "    # MBConv6, k5x5, C=192, L=3\n",
    "    (5, 6, 112, 192, 2, \"Stage_7-1\"),\n",
    "    (5, 6, 192, 192, 1, \"Stage_7-2\"),\n",
    "    (5, 6, 192, 192, 1, \"Stage_7-3\"),\n",
    "    (5, 6, 192, 192, 1, \"Stage_7-4\"),\n",
    "    # MBConv6, k3x3, C=320, L=3\n",
    "    (3, 6, 192, 320, 1, \"Stage_8-1\")\n",
    "]\n",
    "final_activation = \"sigmoid\" if class_type == \"binary\" else \"softmax\"\n",
    "\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3), name=\"Inputs\")\n",
    "x = layers.Rescaling(1./255, name=\"Rescaling\")(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(2, 2), padding=\"same\", use_bias=False, name=\"Stage_1_Conv3x3\")(x)\n",
    "x = layers.BatchNormalization(name=\"Stage_1_BN\")(x)\n",
    "x = Swish(name=\"Stage_1_Swish\")(x)\n",
    "\n",
    "for cfg in model_config:\n",
    "    x = MBConv(*cfg)(x)\n",
    "\n",
    "x = layers.Conv2D(filters=1280, kernel_size=(1, 1), use_bias=False, name=\"Stage_9_Conv1x1\")(x)\n",
    "x = layers.BatchNormalization(name=\"Stage_9_BN\")(x)\n",
    "x = Swish(name=\"Stage_9_Swish\")(x)\n",
    "x = layers.GlobalAveragePooling2D(name=\"Stage_9_Pooling\")(x)\n",
    "x = layers.Dense(category_num, activation=final_activation, name=\"Stage_9_FC\")(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=x)\n",
    "loss_function = f\"{class_type}_crossentropy\"\n",
    "model.compile(loss=loss_function, optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0117ce-0943-43ca-a705-b8f07b16af5e",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfce2fa-9b90-4c67-a7bd-a78d14b3e409",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    epochs=20,\n",
    "    validation_data=valid_set\n",
    ")\n",
    "end = time.time()\n",
    "print(f\"Time spent: {int((end - start) // 60)}m {(end - start) % 60:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7570a4-35b4-40be-8ec6-43eb84e7150a",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730a408f-67dc-4313-8246-66c2473c88a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "epochs = range(1, len(history.history[\"accuracy\"]) + 1)\n",
    "loss = history.history[\"accuracy\"]\n",
    "val_loss = history.history[\"val_accuracy\"]\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation accuracy\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
